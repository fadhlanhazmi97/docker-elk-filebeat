filebeat.inputs:
- type: docker
  combine_partial: true
  containers:
    path: ${LOG_PATH}
    stream: "stdout"
    ids:
      - "*"
  exclude_files: ${EXCLUDE_FILES:".^"}
  exclude_lines: ${EXCLUDE_LINES:".^"}
  ignore_older: 10m

processors:
  # decode the log field (sub JSON document) if JSON encoded, then maps it's fields to elasticsearch fields
- decode_json_fields:
    fields: ${JSON_FIELDS}
    target: ""
    # overwrite existing target elasticsearch fields while decoding json fields    
    overwrite_keys: true
- add_docker_metadata:
    host: "unix:///var/run/docker.sock"

filebeat.config.modules:
  path: ${path.config}/modules.d/*.yml
  reload.enabled: false

# setup filebeat to send output to elasticsearch
output.elasticsearch:
  hosts: ${HOSTS}
  index: ${INDEX}

setup.template.name: "interns"
setup.template.pattern: "interns-*"

logging.level: ${LOGGING_LEVEL}
logging.json: true
logging.to_stderr: false